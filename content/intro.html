<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Introduction</title>
  <meta name="description" content="# Introduction```python tags=["remove_cell"]# Download NLTK resources. Remove code from START_NLTK_TMP to# END_NLTK_TMP to store them in a permanent location...">

  <link rel="canonical" href="https://v4py.github.io//content/intro.html">
  <link rel="alternate" type="application/rss+xml" title="An Introduction to Python for Linguists" href="https://v4py.github.io//feed.xml">

  <meta property="og:url"         content="https://v4py.github.io//content/intro.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Introduction" />
<meta property="og:description" content="# Introduction```python tags=["remove_cell"]# Download NLTK resources. Remove code from START_NLTK_TMP to# END_NLTK_TMP to store them in a permanent location..." />
<meta property="og:image"       content="https://v4py.github.io/images/logo/python.svg" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://v4py.github.io//content/intro.html",
  "headline": "Introduction",
  "datePublished": "2020-03-28T11:42:54+01:00",
  "dateModified": "2020-03-28T11:42:54+01:00",
  "description": "# Introduction```python tags=["remove_cell"]# Download NLTK resources. Remove code from START_NLTK_TMP to# END_NLTK_TMP to store them in a permanent location...",
  "author": {
    "@type": "Person",
    "name": "David Luke≈°, Rudolf Rosa"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://v4py.github.io/",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://v4py.github.io/",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  


  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("https://v4py.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("https://jupyter.korpus.cz", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "An Introduction to Python for Linguists"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "v4py/v4py.github.io",
    ref: "master",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: "python"
    },
    kernelOptions: {
    kernelName: "python3",
    path: ""
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://v4py.github.io"><img src="/images/logo/python.svg" class="textbook_logo" id="sidebar-logo" alt="textbook logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">An Introduction to Python for Linguists</h2>
  <ul class="c-sidebar__chapters">
    
      
      
        <li><h2 class="c-sidebar__title">Table of contents</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/intro">
        <a class="c-sidebar__entry"
          href="/intro.html"
        >
          
            1.
          
          Introduction
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/basics">
        <a class="c-sidebar__entry"
          href="/basics.html"
        >
          
            2.
          
          A tour of Python and NLTK
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/unicode">
        <a class="c-sidebar__entry"
          href="/unicode.html"
        >
          
            3.
          
          Text inside the computer
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/data">
        <a class="c-sidebar__entry"
          href="/data.html"
        >
          
            4.
          
          Getting your data into Python
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/rest">
        <a class="c-sidebar__entry"
          href="/rest.html"
        >
          
            5.
          
          Working with online resources
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/case">
        <a class="c-sidebar__entry"
          href="/case.html"
        >
          
            6.
          
          Case studies
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/case/collocations">
              <a class="c-sidebar__entry"
                href="/case/collocations.html"
              >
                
                  6.1
                
                Determining collocation strength
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/case/keywords">
              <a class="c-sidebar__entry"
                href="/case/keywords.html"
              >
                
                  6.2
                
                Keyword analysis: Donald Trump's speeches
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/outro">
        <a class="c-sidebar__entry"
          href="/outro.html"
        >
          
            7.
          
          Parting words
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      
        <li><h2 class="c-sidebar__title">Links</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://www.visegradfund.org/">
        <a class="c-sidebar__entry"
          href="https://www.visegradfund.org/"
        >
          
          Sponsored by the Visegrad Fund
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://ufal.mff.cuni.cz/">
        <a class="c-sidebar__entry"
          href="https://ufal.mff.cuni.cz/"
        >
          
          √öFAL MFF UK
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://korpus.cz/">
        <a class="c-sidebar__entry"
          href="https://korpus.cz/"
        >
          
          Czech National Corpus
        </a>
      </li>

      
      

      

      
      

      

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/assets/images/download-solid.svg" alt="Download" /></button>
    <div class="download-buttons">
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><img src="/assets/images/list-solid.svg" alt="Search" />   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/search.html" class="topbar-right-button" id="search-button">
    <img src="/assets/images/search-solid.svg" alt="Search" />
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <h1 id="introduction">Introduction</h1>

<p>```python tags=[‚Äúremove_cell‚Äù]</p>
<h1 id="download-nltk-resources-remove-code-from-start_nltk_tmp-to">Download NLTK resources. Remove code from START_NLTK_TMP to</h1>
<h1 id="end_nltk_tmp-to-store-them-in-a-permanent-location-instead-of-a">END_NLTK_TMP to store them in a permanent location instead of a</h1>
<h1 id="temporary-directory">temporary directory.</h1>
<h1 id="-start_nltk_tmp-">‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî START_NLTK_TMP ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</h1>
<p>import os
import tempfile</p>

<p>nltk_data = os.path.join(tempfile.gettempdir(), ‚Äúv4py‚Äù, ‚Äúnltk_data‚Äù)
os.makedirs(nltk_data, exist_ok=True)
os.environ[‚ÄúNLTK_DATA‚Äù] = nltk_data</p>
<h1 id="--end_nltk_tmp--">‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî- END_NLTK_TMP ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-</h1>

<p>import nltk</p>

<p>nltk.download([‚Äúpunkt‚Äù, ‚Äústopwords‚Äù])</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- started programming at uni, so it's never too late :)
- probably **the most useful skill** since learning to read

The source code of this book lives in a [GitHub
repository](https://github.com/v4py/v4py.github.io). Please open issues
with requests for clarification, tips for improvement, or even just
typos!

# Python gives you wings!

So what is this Python thing all about?

![Python XKCD](https://imgs.xkcd.com/comics/python.png)

Credit: Randall Munroe, XKCD, &lt;https://xkcd.com/353/&gt;

GvR, The Making of Python: a teaching language, originally for small
programs -&gt; teachability, understandability and readability matters
(unlike R)

Coming from R: Python is a general purpose language -&gt; maybe a bit
harder to find one's way around the landscape for a particular purpose
(e.g. statistics or data science), but it pays off in that you're not
limited by the one intended use, which is a good thing whenever you
embark on a bigger project. R starts to get really ugly really quickly
when using it for anything that's not easily achieved by an existing
library, and though it deserves an honorable mention for having a lot of
libraries with useful functionality, some of them very well-designed
(tidyverse), it's one of the laws of programming that there will always
be at least this one thing in your project that there is no existing
library for (or maybe there is, but you can't seem to find it).

# Target audience

NOTE: transform questions into statements about expected audience.

- Who has programmed before? In what language(s)? Python?
- What's your academic field? Linguistics, history, digital
  humanities...?
- Who is reasonably familiar with working with language data on a
  computer (e.g. corpora etc.)?
- Who knows what regular expressions are? Who uses them?
- What are you hoping to learn this week?

# About Python

&lt;!-- #md tags=["epigraph"] --&gt;

&gt; On second thought, let's not go to Camelot. 'Tis a silly place.
&gt;
&gt; -- King Arthur, Monty Python and the Holy Grail

&lt;!-- #endmd --&gt;

- a simple, fun and approachable programming language
- FLOSS (Free, Libre, Open-Source Software) √ó e.g. Microsoft Word
- created in 1991 by Guido van Rossum
- why is it named Python?

Using Python:

- Python 2 vs. **Python 3**

# How to use this book

This book actually consists of a series of [Jupyter
notebooks](https://jupyter.org/), which is a file format, recognizable
by its `.ipynb` extension, which intermixes expository prose with
programming code. It can be opened using the
[JupyterLab](https://jupyterlab.readthedocs.io/) application, which runs
in your browser. In the notebooks, code is stored inside code cells
which can be modified and run at will, which encourages interactive
exploration and makes learning easier. This is what a code cell looks
like:

```python
1 + 1
</code></pre></div></div>

<p>You can see the code cell‚Äôs output right below it ‚Äì in this case, it‚Äôs
a plain old <code class="language-plaintext highlighter-rouge">2</code>.</p>

<p>If you can, it‚Äôs a great idea to follow along in JupyterLab, running the
code in each chapter of the book yourself and tinkering with it. There
are several options for that. The easiest one is to use either the <strong>‚ñ∂
mybinder.org</strong> or <strong>‚ñ∂ jupyter.korpus.cz</strong> buttons at the top of the
page, which will take care of everything for you and open an interactive
version of this text in your browser.</p>

<p>Note that the second button requires that you have an account at
<a href="https://jupyter.korpus.cz">https://jupyter.korpus.cz</a> (attendees of the V4Py summer school do),
and due to some bugs in the software which makes this possible, it
doesn‚Äôt work as intended if you‚Äôre not already logged in. In that case:</p>

<ol>
  <li>Click on the button once and log into JupyterLab.</li>
  <li>Close the JupyterLab tab.</li>
  <li>Click on the button a second time. JupyterLab should now
automatically open the appropriate notebook.</li>
  <li>If that doesn‚Äôt happen, try reloading the page.</li>
</ol>

<p>If you want to install Python on your own computer and run JupyterLab
locally, I would suggest using <a href="https://www.anaconda.com/distribution/">the Anaconda
Distribution</a>, which installs
Python alongside many popular additional packages and libraries for data
analysis. In that case, you‚Äôll be opening JupyterLab via the <a href="https://docs.anaconda.com/anaconda/navigator/">Anaconda
Navigator</a>, and you‚Äôll
need to <a href="https://github.com/v4py/v4py.github.io/archive/master.zip">download the notebooks
manually</a>
(after unzipping, the notebooks are in the <code class="language-plaintext highlighter-rouge">content/</code> subdirectory).</p>

<p>If you want to learn more about using notebooks, <a href="https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks">here‚Äôs a gallery of
interesting notebooks to help you get acquainted with the
format</a>,
including some introductory tutorials on how to use it right. The
JupyterLab notebook user interface is described in more detail in <a href="https://jupyterlab.readthedocs.io/en/latest/user/notebook.html">their
docs</a>.
Finally, some usage tips which I personally find useful can be found in
the <a href="https://dlukes.github.io/jupyter-magic.html">this blog post</a></p>

<h1 id="diving-right-in-a-frequency-analysis-of-this-text">Diving right in: a frequency analysis of this text</h1>

<p>To get our feet wet, let‚Äôs do a quick frequency analysis of the text
you‚Äôre currently reading. If you‚Äôve never programmed before, don‚Äôt worry
if parts (or all) of the code below seems a little mysterious!  We‚Äôll
cover all of that in much more detail in the following chapters.
However, before we dive into the particulars, I think it‚Äôs a good idea
to get acquainted with what actual useful Python code looks like, so
that we have a general picture of where we‚Äôre headed. Without a global
perspective and a clear goal in our heads, it‚Äôs easy to get discouraged
by the many seemingly unconnected details that await us along the way.</p>

<p>So take a while to look at each code chunk below, try and figure out
what its purpose might be and how it achieves it, try and discover
repeating patterns in Python‚Äôs syntax and their meaning. Read the
commentary and let the programming vocabulary soak into your brain. It‚Äôs
alright to be confused, it‚Äôs OK not to understand precisely what each
and every word means. The goal at this point is to get familiar with how
Python code looks and how the terminology sounds, even if you don‚Äôt
fully understand what‚Äôs happening yet.</p>

<!-- #md tags=["popout"] -->

<p><strong>HTML</strong> is the <a href="https://en.wikipedia.org/wiki/HTML">Hypertext Markup
Language</a> and it‚Äôs what web pages
are built from, specifically their structure. Layout is mostly done
using <a href="https://en.wikipedia.org/wiki/Cascading_Style_Sheets">CSS</a> and
interactive features with
<a href="https://en.wikipedia.org/wiki/JavaScript">JavaScript</a>.</p>

<!-- #endmd -->

<p>We start by <strong>importing</strong> <code class="language-plaintext highlighter-rouge">HTMLSession</code> from the
<a href="http://html.python-requests.org"><code class="language-plaintext highlighter-rouge">requests_html</code></a> <strong>library</strong>, which
contains functionality related to fetching HTML pages from the web.  We
create a fresh <code class="language-plaintext highlighter-rouge">HTMLSession</code> <strong>object</strong> and store it in the <code class="language-plaintext highlighter-rouge">session</code>
<strong>variable</strong>. Think of it as a simple web browser inside Python.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">requests_html</span> <span class="kn">import</span> <span class="n">HTMLSession</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">HTMLSession</span><span class="p">()</span>
</code></pre></div></div>

<!-- #md tags=["popout"] -->

<p><strong>HTTP</strong> stands for <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">Hypertext Transfer
Protocol</a>.
It‚Äôs the main protocol used for sending around data on the web.</p>

<!-- #endmd -->

<p>We can fetch the page you‚Äôre currently reading by calling the <code class="language-plaintext highlighter-rouge">get()</code>
<strong>method</strong> of the <code class="language-plaintext highlighter-rouge">session</code> object and passing it the link to this
website as an <strong>argument</strong>. We get back an HTTP response.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">link</span> <span class="o">=</span> <span class="s">"https://v4py.github.io/intro.html"</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
</code></pre></div></div>

<p>Inspecting the <code class="language-plaintext highlighter-rouge">response</code> variable, we see <code class="language-plaintext highlighter-rouge">&lt;Response [200]&gt;</code>. <code class="language-plaintext highlighter-rouge">200</code> is
the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">HTTP status
code</a> which
indicates that all went well with our request and we received a
sucessful response.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span>
</code></pre></div></div>

<p>If we don‚Äôt know or remember which HTTP status code is which, we can
check that everything is fine by inspecting the <code class="language-plaintext highlighter-rouge">.ok</code> <strong>attribute</strong> on
the <code class="language-plaintext highlighter-rouge">response</code> object.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span><span class="o">.</span><span class="n">ok</span>
</code></pre></div></div>

<p>The contents of the web page are stored in the <code class="language-plaintext highlighter-rouge">.html</code> attribute of the
<code class="language-plaintext highlighter-rouge">response</code> object.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span><span class="o">.</span><span class="n">html</span>
</code></pre></div></div>

<p>That attribute is itself an object with attributes and methods of its
own, which allow us to inspect it and manipulate it. For instance, it
has in turn its own <code class="language-plaintext highlighter-rouge">.html</code> attribute, which contains the raw HTML code
underlying the web page you‚Äôre reading, stored as a <strong>string</strong> of
<strong>characters</strong>. We can take a look at a <strong>slice</strong> of the first 50
characters of the string, just to make sure we downloaded the right
document.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">html</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
</code></pre></div></div>

<p>Uh-oh, I don‚Äôt remember reading anything about any doctypes at the
beginning of this text. What‚Äôs this all about? Well this is all part of
the HTML language, which tells your browser how to display this web
page. Trouble is, from our point of view as linguists, this is just junk
that we need to get rid of. One thing we could try is the <code class="language-plaintext highlighter-rouge">.text</code>
attribute, which extracts only the text parts of a web page.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the first 50 characters
</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">text</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the last 50 characters
</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="mi">50</span><span class="p">:]</span>
</code></pre></div></div>

<p>That looks somewhat better, but there‚Äôs clearly still some ‚Äújunk‚Äù left.
Turns out that the ‚Äútext‚Äù content of an HTML page includes not only all
the stuff that‚Äôs visible on the page (navigation elements, button
labels, and other things we probably want to exclude from our analysis),
but also invisible things like JavaScript programs which add
interactivity to the page (surrounded by <code class="language-plaintext highlighter-rouge">&lt;script/&gt;</code> tags) or CSS styles
which define the layout and other aesthetic aspects of the page
(surrounded by <code class="language-plaintext highlighter-rouge">&lt;style/&gt;</code> tags).</p>

<p>Ideally, we‚Äôd like to get rid of all of this. How to achieve that? We
first need to figure out which parts of the HTML enclose the content
we‚Äôre interested in. For that, we‚Äôll use our browser‚Äôs inspector tools.
If you right click anywhere on this page, you should get a menu where on
of the items says something like <em>Inspect</em> or <em>Inspect Element</em>. Click
on that and a pane will open beside the page which lets you peek under
the hood of this page. If you right click on this paragraph specifically
and select <em>Inspect Element</em>, the inspector will focus on where in the
HTML hierarchy this particular paragraph is placed.</p>

<p><img src="/content/images/intro/inspector.png" alt="Firefox inspector screenshot" /></p>

<p>We can see that this paragraph is contained with a <code class="language-plaintext highlighter-rouge">&lt;div/&gt;</code> HTML element
which has a class of <code class="language-plaintext highlighter-rouge">rendered_html</code>, among others. This sounds like a
property which could be true of all the interesting content on this page
‚Äì after all, we know it was <em>rendered</em> from a Jupyter notebook to HTML
‚Äì so let‚Äôs go on a limb here and retrieve all of those <code class="language-plaintext highlighter-rouge">divs</code> using the
<code class="language-plaintext highlighter-rouge">.find()</code> method. This method uses <a href="https://www.w3schools.com/cssref/css_selectors.asp">CSS
selectors</a> to slice
and dice the page; all we need to know right now is that the syntax to
find all HTML elements of a certain class is to prefix the class name
with a period, so <code class="language-plaintext highlighter-rouge">.rendered_html</code> in our case. We get back a <strong>list</strong>
of <code class="language-plaintext highlighter-rouge">divs</code>; the <code class="language-plaintext highlighter-rouge">clean=True</code> <strong>keyword argument</strong> makes sure that we
throw away those pesky invisible <code class="language-plaintext highlighter-rouge">&lt;script/&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;style/&gt;</code> tags, if
any.</p>

<p>```python tags=[‚Äúfull_width‚Äù]
divs = response.html.find(‚Äú.rendered_html‚Äù, clean=True)
divs[:5]</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;!-- TODO: explain escape sequence or later? --&gt;

Each of these `divs` has a `.text` attribute, which hopefully contains
reasonable text and not some junk. We'd like to lump it all together
into one long string before moving on to further processing, because we
don't really care which part of the text was in which `div`, we just
want to have it all in one place to make things easy. So we can join all
of those `.text` attributes into one string by splicing a **newline**
character, written using the **escape sequence** `"\n"`, in between
every two pieces of text.

```python
string = "\n".join(div.text for div in divs)
string[:30]
</code></pre></div></div>

<!-- TODO: explain function vs. method or later? -->

<p>This is starting to look good! We‚Äôve possibly thrown out some stuff that
could have been included, like the chapter title, but it‚Äôs definitely
much better than accidentally including all that JavaScript junk in our
analysis. Just to see how much stuff we‚Äôve gotten rid of, we can compare
the number of characters using the <code class="language-plaintext highlighter-rouge">len()</code> <strong>function</strong>.</p>

<!-- TODO: add something like "we've cut it roughly in half!" based on how -->
<!-- much it turns out to be in the end -->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">full_text</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">text</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
</code></pre></div></div>

<p>Now in order to do a frequency analysis, we need to split that text into
words or <strong>tokens</strong>, which is a technical term used when we want to
avoid the kind of philosophical hairsplitting that linguists sometimes
engage in with respect to what is or is not a word. Referring to words
as ‚Äòtokens‚Äô is basically a way of saying, ‚ÄúI don‚Äôt want to pick a fight
about the precise meaning of ‚Äòword‚Äô right now, I made a pragmatic
decision to split the text into pieces which broadly make sense, but of
course reasonable people might disagree on the details.‚Äù It also allows
us to be precise that we are referring to specific <em>instances</em> of words.
The word ‚Äòword‚Äô is ambiguous, a sentence like ‚ÄúI know I screwed up.‚Äù can
be described as containing either 5 (total running) words or 4
(different) words. If we want to avoid confusion, we can say instead
that it consists of <strong>5 tokens</strong> and <strong>4 types</strong>.</p>

<p>Word-splitting or <strong>tokenization</strong> is a trickier problem than it might
seem at first glance, because punctuation keeps getting in the way. So
let‚Äôs not do it manually ourselves, let‚Äôs use instead the
<code class="language-plaintext highlighter-rouge">word_tokenize()</code> function in the <a href="http://www.nltk.org/"><code class="language-plaintext highlighter-rouge">nltk</code></a>
library, which hopefully covers some of the edge cases we wouldn‚Äôt think
of right off the bat if we were to implement it ourselves off the top of
our head. This function <strong>returns</strong> a list of strings, and again we can
do a sanity check by inspecting a slice of it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">tokenized</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tokenized</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">115</span><span class="p">]</span>
</code></pre></div></div>

<p>Looks fine. Notice that before tokenizing the string, we converted in to
<strong>lowercase</strong> using the <code class="language-plaintext highlighter-rouge">.lower()</code> <strong>method</strong>. This is because in our
frequency analysis, we probably don‚Äôt want to make a distinction between
e.g. <code class="language-plaintext highlighter-rouge">token</code> and <code class="language-plaintext highlighter-rouge">Token</code>. They refer to the same thing, so they should
be counted together, but the computer doesn‚Äôt know that, as far as it‚Äôs
concerned, <code class="language-plaintext highlighter-rouge">token</code> is as different from <code class="language-plaintext highlighter-rouge">Token</code> as it is from
<code class="language-plaintext highlighter-rouge">grapefruit</code>, so it‚Äôs our job to make them exactly the same by
lowercasing everything beforehand. We can measure the length of the list
and thus get the number of tokens using the <code class="language-plaintext highlighter-rouge">len()</code> function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">tokenized</span><span class="p">)</span>
</code></pre></div></div>

<p>That‚Äôs quite a lot, thanks for reading so far!</p>

<p>But hang on, that count is likely to be somewhat inflated. First of all,
a lot of the tokens in the <code class="language-plaintext highlighter-rouge">tokenized</code> list are junk, at least
linguistically speaking, they are special characters related to the
notebook format.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenized</span><span class="p">[:</span><span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<p>Second of all, it doesn‚Äôt take a linguist to realize that the most
common words in an English text will be words like <code class="language-plaintext highlighter-rouge">a</code> or <code class="language-plaintext highlighter-rouge">the</code>. We
probably don‚Äôt want to include those in our frequency analysis, since
they‚Äôre not very interesting, they don‚Äôt tell us a lot. Luckily, <code class="language-plaintext highlighter-rouge">nltk</code>
has a list of these uninteresting <strong>stopwords</strong> for English which we can
load and store in a <strong>set</strong>, so that we can quickly check if a given
token is a stopword or not. The stopwords are stored in their lowercase
form, so it comes in handy that we already lowercased our input string
prior to tokenizing it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="n">stop_list</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">stop_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stop_list</span><span class="p">)</span>
<span class="n">stop_list</span><span class="p">[:</span><span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<p>We can now get rid of any unwanted tokens. The following code snippet is
a bit more complicated than the previous ones, it involves some
non-linear <strong>control flow</strong>, which is a fancy way of saying the code
doesn‚Äôt just linearly execute from top to bottom, but it can run around
in circles for a while (the <strong>for</strong> statement) or potentially skip some
parts depending on whether a condition <strong>evaluates</strong> to true or false
(the <strong>if</strong> statement).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a new empty
</span><span class="n">cleaned</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># iterate over all the tokens in the tokenized list
</span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="p">:</span>
    <span class="c1"># check if current token is "interesting"
</span>    <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_set</span><span class="p">:</span>
        <span class="c1"># if so, append it to the cleaned list
</span>        <span class="n">cleaned</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
</code></pre></div></div>

<!-- #md tags=["popout"] -->

<p>‚Ä° At least partially ‚Äì if you actually inspect the contents of <code class="language-plaintext highlighter-rouge">cleaned</code>,
you‚Äôll see that it still contains many tokens, like <code class="language-plaintext highlighter-rouge">cells</code> or
<code class="language-plaintext highlighter-rouge">metadata</code>, which look like regular words, but they don‚Äôt occur in this
text, they‚Äôre part of the notebook format structure.</p>

<!-- #endmd -->

<p><code class="language-plaintext highlighter-rouge">cleaned</code> is a lot shorter than <code class="language-plaintext highlighter-rouge">tokenized</code>, so it looks like it
worked!‚Ä° Note how Python uses <strong>indentation</strong> to encode the hierarchy
of <strong>statements</strong> in the code: everything which is indented under the
<strong>for-loop header</strong> on the second line is part of the <strong>for-loop body</strong>
and gets executed for each token in the tokenized list. Similarly,
everything indented under the <strong>if header</strong> only gets executed if the
conditional <strong>expression</strong> is satisfied. By dedenting, we escape the
tyranny of those fors and ifs, so that the last line gets executed only
once, after the for-loop has completed.</p>

<p>Notice also that with suitably chosen variable names, Python code can
read almost like English. Readability is one of Python‚Äôs main strengths,
though it can sometimes be a pitfall for beginners ‚Äì when they‚Äôre not
sure how to do something in Python, they try to write it in an
English-like way and hope for the best, but this approach can yield
valid Python code which however does something different than the plain
English interpretation would suggest.</p>

<p>We are now finally in a position to create a <strong>frequency distribution</strong>,
using the <code class="language-plaintext highlighter-rouge">nltk.FreqDist</code> <strong>class</strong>. It‚Äôs easy, we just pass it our list
of clean tokens.</p>

<!-- #md tags=["popout"] -->

<p>Each object in Python has a <strong>type</strong>. Some of those are built-in, like
strings, lists or sets. But users can also define new types of their
own; those are called <strong>classes</strong>. <code class="language-plaintext highlighter-rouge">nltk.FreqDist</code> is one of those
user-defined types.</p>

<!-- #endmd -->

<p>```python tags=[‚Äúoutput_scroll‚Äù]
freq_dist = nltk.FreqDist(cleaned)
freq_dist</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
We can access individual **values** inside the frequency distribution by
requesting them using the corresponding **key**.

```python
freq_dist["python"]
</code></pre></div></div>

<p>We can also list the top $n$ items using the <code class="language-plaintext highlighter-rouge">.most_common()</code> method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">freq_dist</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p>Based on the most frequent lexical items, it looks like this is a text
about Python programming and language data! That checks out.</p>

<p>Finally, we can visualize this result using a wordcloud, to get a quick
and intuitive overview of these important words.</p>

<p>```python tags=[‚Äúfull_width‚Äù]
from corpy.vis import wordcloud</p>

<p>wordcloud(freq_dist, size=(800, 400), rounded=True)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Whew! That was actually a lot of work. Now that we've figured out how to
do this, we could package all of these steps into a reusable recipe, so
that we don't have to re-cobble all of this together if we want to run a
same analysis on a different chapter. We can do so by writing a
function. Again, as with for-loops and if statements, everything that's
indented under the function header starting with `def` is part of the
function body, and will be run step by step each time the function is
**called**.

```python
def chapter_wordcloud(link, size=(800, 400), rounded=True):
    session = HTMLSession()
    response = session.get(link)
    divs = response.html.find(".rendered_html", clean=True)
    string = "\n".join(div.text for div in divs)
    tokenized = nltk.word_tokenize(string.lower())
    stop_set = set(nltk.corpus.stopwords.words("english"))
    cleaned = []
    for token in tokenized:
        if token.isalpha() and token not in stop_set:
            cleaned.append(token)
    # if we want just the wordcloud, we can also directly create it from
    # a list of tokens, without making an intermediate nltk.FreqDist
    return wordcloud(cleaned, size=size, rounded=rounded)
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">return</code> keyword specifies what the result is that the function
spits out at the other end. Once the function reaches a return
statement, it stops execution and gives the result back to whoever
called the function.</p>

<p>We can now easily create a wordcloud based on the final chapter of this
book, for comparison.</p>

<p>```python tags=[‚Äúfull_width‚Äù]
chapter_wordcloud(‚Äúhttps://v4py.github.io/outro.html‚Äù)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Indeed, we can use this function on any chapter in any online book
created (much like the present book) with the [jupyter-book]() package,
because they all use the same HTML structure. For instance, here's a
wordcloud of the chapter on [*Regular
Expressions*](https://www.textbook.ds100.org/ch/08/text_regex.html) from
the book [*Principles and Techniques of Data
Science*](https://www.textbook.ds100.org/).

```python tags=["full_width"]
chapter_wordcloud("https://www.textbook.ds100.org/ch/08/text_regex.html")
</code></pre></div></div>

<p>This is the real power of programming: once you‚Äôve figured out and
tweaked a processing and analysis recipe, you can apply it to similar
data with lightning speed and each time consistently in exactly the same
way.</p>

<p>To wrap up, let me reiterate that I realize this is a lot to take in if
this is your first time seeing Python code, and even more so if this is
your first time seeing any programming language code whatsoever. Again,
it‚Äôs totally fine if you don‚Äôt understand all the details at this point.
I encourage you to revisit this extended worked example once you‚Äôre done
reading the book, as a way to reflect on what you‚Äôve learned and bring
it all together.</p>

<h1 id="nltk-book">NLTK Book</h1>

<p>A great, longer free resource. <a href="http://www.nltk.org/book/">http://www.nltk.org/book/</a></p>

<p><img src="./nltk_book.jpg" alt="NLTK Book" /></p>

<p>Credit: ???</p>

<h1 id="the-nlp-pipeline">The NLP pipeline</h1>

<p>NOTE: maybe leave this out? Not strictly necessary, this is probably
better to discuss in class, plus I shouldn‚Äôt rely too much on NLTK Book
materials for licensing reasons.</p>

<p><img src="./dialogue.png" alt="NLP" /></p>

<p>Credit: ???</p>

<h1 id="overview">Overview</h1>

<ul>
  <li>Python basics (functions, control flow, collections)</li>
  <li>The NLTK <a href="http://www.nltk.org/">package</a> &amp;
<a href="http://www.nltk.org/book">book</a> as a good starting point for people
interested in language data</li>
  <li><a href="https://dlukes.github.io/unicode.html">How text is represented inside
computers</a></li>
  <li>Regular expressions in Python</li>
  <li>Accessing web services (‚ÄúREST APIs‚Äù) from Python &amp; Automatic
annotation of language data (tagging, parsing) ‚Äì both courtesy of
<a href="https://ufal.mff.cuni.cz/rudolf-rosa">Rudolf Rosa</a></li>
  <li>Getting data into Python (raw text &amp; tabular data)</li>
  <li>Some visualizations (dispersion plots, wordclouds)</li>
  <li>Case studies: collocation strength, keyword analysis</li>
</ul>

<!-- - Hackathon on Friday! -->

<h1 id="info-about-jupyter-notebook--jupyterlab">Info about Jupyter Notebook / JupyterLab</h1>

<p>This course consists of Python notebooks which you can open and interact
with using either the new
<a href="https://jupyterlab.readthedocs.io">JupyterLab</a> environment or the
legacy <a href="https://jupyter-notebook.readthedocs.io">Jupyter Notebook</a>
interface. For more information on both of these, including tutorials on
how to use them, check out the <a href="https://jupyter.org">Project Jupyter
website</a>. Some usage tips are also provided here as
<a href="TODO/Make the most of Jupyter notebooks">Appendix TODO</a>.</p>

<p>The easiest way to run JupyterLab or Jupyter Notebook is by using a
cloud service like <a href="https://mybinder.org">Binder</a>. With Binder, you
don‚Äôt have to worry about installing anything on your computer, you just
open a link in your browser and start playing around with the target
notebook right away. At the beginning of each chapter, we‚Äôll therefore
provide Binder links to the corresponding notebooks for your
convenience. They look like this:</p>

<p><a href="TODO">Binder link</a></p>

<p>Click on it to try it out!</p>

<p>The second most convenient way is to install the <a href="https://www.anaconda.com/distribution/">Anaconda Python
distribution</a>, because both
JupyterLab and Jupyter Notebook come bundled with it. After
installation, run the <em>Anaconda Navigator</em> program, which provides
buttons to launch them. You‚Äôll also have to manually download the
course‚Äôs notebooks to your computer, so that you can work with them. All
of the course‚Äôs notebooks are available in its <a href="TODO">GitHub
repository</a>.</p>

<p>More advanced users will probably be aware that both can also be
installed using standard command line Python package managers like
<code class="language-plaintext highlighter-rouge">conda</code> or <code class="language-plaintext highlighter-rouge">pip</code>. If the previous sentence sounds like gibberish to you,
don‚Äôt worry, you can safely ignore it :)</p>

<!-- vim: set spell spelllang=en: -->

            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  

  
</nav>

              <footer>
  <p class="footer"></p>
</footer>

            </div>

        </div>
      </main>
    </div>
  </body>
</html>
